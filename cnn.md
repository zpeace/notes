
Actively interested in learning about deep learning and other related subjects.

It's not just about answering questions; even more so, it is about asking the right questions.

I will be demanding, more demanding than most.

Think actively about the creative process. Think explicitly about the process and talk about it.

When you learn the theory, you should try to calculate some toy cases, and think of some explicit basic exaples.


1. List applications of computer vision.
2. What are challenges?
    - huge data: fully connected layer will contain humongous data
    - CNN is more appropriate
3. What is filter/kernel?
4. 

5. Regularization helps preventing overfitting.
    - L2 regularization can be thought as weight decaying.

6. Why regularization reduces overfitting?
    - Weight decay is simplifying the nets.
    - for activation function tanh(), regularization is making the nets more linear.
